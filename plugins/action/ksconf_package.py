# -*- coding: utf-8 -*-
#
# ACTION:  (This runs on the controller!)
#


from __future__ import absolute_import, division, print_function

import datetime
import hashlib
import json
import os
import re
from io import StringIO
from pathlib import Path, PurePath

from ansible.errors import AnsibleError
from ansible.module_utils._text import to_text
from ansible.module_utils.parsing.convert_bool import boolean
from ansible.parsing.vault import VaultEditor, VaultLib, b_HEADER as VAULT_HEADER
from ansible.plugins.action import ActionBase
from ansible.template import Templar
from ansible.utils.display import Display

from ansible_collections.cdillc.splunk.plugins.module_utils.ksconf_shared import (
    __version__ as collection_version, check_ksconf_version, temp_decrypt)


display = Display()
MODULE_NAME = "ksconf_package"


JINJA_HANDLERS = ["ansible", "ansible-jinja"]
# For now this is the same
TEMPLATE_HANDLERS = JINJA_HANDLERS


ksconf_min_version = (0, 13, 7)
ksconf_min_version_text = ".".join(f"{i}" for i in ksconf_min_version)

ksconf_version = check_ksconf_version()
if ksconf_version < ksconf_min_version:
    raise AnsibleError(f"ksconf version {ksconf_version} is older than v{ksconf_min_version_text}."
                       "  This may result in unexpected behavior.  Please upgrade ksconf.")


from ksconf.app.manifest import create_manifest_from_archive, load_manifest_for_archive  # noqa
from ksconf.builder.cache import FileSet, fingerprint_stat  # noqa
from ksconf.conf.parser import ConfParserException, parse_string  # noqa
from ksconf.layer import LayerRenderedFile, layer_file_factory, register_file_handler  # noqa
from ksconf.package import AppPackager  # noqa
from ksconf.util.file import atomic_open  # noqa


def validate_rendered(logical_path: Path, template_path: Path, value: str):
    if logical_path.suffix in (".conf", ".meta"):
        try:
            parse_string(value, name=os.fspath(template_path))
        except ConfParserException as e:
            raise AnsibleError(f"Output generated by template {template_path.name} is invalid. "
                               f"Path: {logical_path}  Parsing error: {e}")


@register_file_handler("ansible-jinja", priority=10, enabled=False)
class LayerFile_AnsibleJinja2(LayerRenderedFile):
    """
    Custom ansible render handler for Ksconf layers
    This makes a callback into Ansible's template functionality for actual rendering
    """
    SUFFIX_MATCH = {".j2"}

    module: ActionBase = None
    _templar: Templar = None

    @classmethod
    def set_module(cls, module: ActionBase):
        cls._templar = module._templar

    @classmethod
    def match(cls, path: PurePath) -> bool:
        return path.suffix in cls.SUFFIX_MATCH

    @property
    def templar(self) -> Templar:
        # Use context object to 'cache' the templar
        if not hasattr(self.layer.context, "ansible_templar"):
            self.layer.context.ansible_templar = self._build_templar()
        return self.layer.context.ansible_templar

    def _build_templar(self):
        updates = {
            "searchpath": [os.fspath(self.layer.root)]
        }
        if self.layer.context.template_variables:
            updates["available_variables"] = self.layer.context.template_variable
        templar = self._templar.copy_with_new_env(**updates)
        return templar

    def render(self, template_path: Path) -> str:
        # Note that because we do not call generate_ansible_template_vars(), we cannot make use
        # of 'template_*' variables (like path/mtime/host).  These tend to interfere with
        # idempotent behavior so not a big loss)
        display.vv(f"Decrypting {template_path} which will become {self.logical_path}")
        template = template_path.read_text()
        value = self.templar.do_template(template, escape_backslashes=False)

        validate_rendered(self.logical_path, template_path, value)
        return value


@register_file_handler("ansible-vault", priority=10, enabled=False)
class LayerFile_AnsibleVault(LayerRenderedFile):
    """
    Custom ansible render handler for Ksconf layers
    This makes a callback into Ansible's decrypt functionality for encrypted files

    Why this approach?
    ------------------
    This implementation requires that all vaulted files be explicitly marked with the `.vault`
    suffix, and of course, the file handler must be enabled at run-time.

    In contrast, transparent support for ansible vault files would be ideal because (1) there's no
    need for special suffixes which, thus better confirming with Ansible's normal behavior, and (2)
    it would enable nesting, thus it making it possible to vault encrypt a .j2 template.  However,
    this approach was not chosen because it would require a lower-level changes of the LayerFile
    handling or some type of "file open" interception within ksconf itself.  Also, this requires a
    certain degree of runtime overhead where every open file must be inspected for magic headers.

    A third option would be to check for the vault header within match(), and then support some kind
    of "continue" flag (thus allowing for multiple handlers to be chained) instead of just one.  But
    again, this would require core changes to ksconf layering behavior. which at least for now,
    seems avoidable.
    """
    SUFFIX_MATCH = {".vault"}

    module: ActionBase = None
    _vault: VaultLib = None

    # Note that there are *many* temporary files created during a packaging operation.  Shredding
    # just one copy may be irrelevant to the big picture.  (Generally speaking, if your Ansible
    # controller is compromised, you've already lost.  But secure deletion is one step closer.
    use_secure_delete = True

    @classmethod
    def set_vault(cls, vault: VaultLib):
        cls._vault = vault

    @classmethod
    def match(cls, path: PurePath) -> bool:
        return path.suffix in cls.SUFFIX_MATCH

    @property
    def vault(self) -> VaultLib:
        return self._vault

    def render(self, template_path: Path) -> str:
        display.vv(f"Decrypting {template_path} which will become {self.logical_path}")
        b_value: bytes = self.vault.decrypt(template_path.read_bytes())
        value = b_value.decode("utf-8")
        validate_rendered(self.logical_path, template_path, value)
        return value


def translate_ksconf_vars(value):
    """
    Translate any '[[var]]' format into '{{var}}' format for ksconf.  This
    allows playbook authors to write:
        [[var]]
    instead of:
        {{'{{'}}version{{'}}'}}
    or, worse yet:
        {% raw %}{{ var }}{% endraw %}
    """
    if value:
        return re.sub(r'\[\[(\s*[\w_]+\s*)\]\]', r"{{\1}}", value)
    return value


def failed(msg, *args, **kwargs):
    d = {"failed": True,
         "msg": msg}
    d.update(*args, **kwargs)
    return d


def is_vault_file(path: Path):
    with open(path, 'rb') as f:
        chunk = f.read(100)
    return chunk.startswith(VAULT_HEADER)
    # Unsure why this wasn't working....
    # return is_encrypted_file(f, len(VAULT_HEADER))


class ActionModule(ActionBase):

    # Don't support moving files.  Everything is done on the controller
    TRANSFERS_FILES = False

    PARAMS_NO_CACHE = {"source", "context", "cache_storage"}

    def filter_params(self, params: dict) -> dict:
        params = dict(params)
        # Drop unwanted params and normalize
        for key in self.PARAMS_NO_CACHE:
            del params[key]
        # Simplify layers to lists of [include/exclude, layer_name]
        params["layers"] = [[mode, pattern] for layer in params["layers"]
                            for mode, pattern in layer.items() if pattern]
        return params

    def get_cache_id(self, source: Path, params: dict) -> str:
        # Build a unique fingerprint for the combination of (1) input parameters,
        # and (2) signature of the 'source' directory
        source = Path(source)
        cache_params = self.filter_params(params)
        h = hashlib.new("sha256")
        content = json.dumps(cache_params, indent=0, sort_keys=True)
        h.update(content.encode("utf-8"))
        param_sig = h.hexdigest()
        return f"{source.name}-@-{param_sig[:32]}"

    def save_cached_execution(self,
                              cache_file: Path,
                              source: str,
                              inputs: dict,
                              outputs: dict,
                              output_file: Path) -> bool:

        cache_data = {
            "inputs": self.filter_params(inputs),   # Not really used; for troubleshooting
            "outputs": outputs,
            "version": collection_version,
        }
        assert cache_data["outputs"]["archive"] == os.fspath(output_file)

        # TODO:  Optimize this so we don't have to recalculate this
        source_fileset = FileSet.from_filesystem(Path(source), fingerprint=fingerprint_stat)
        cache_data["source"] = source_fileset.to_cache()

        cache_data["output_fingerprint"] = fingerprint_stat(output_file)

        display.vvv(f"Cache data to {cache_file} with content:  {cache_data!r}")

        try:
            with atomic_open(cache_file, ".tmp", "w") as cache_fp:
                # TODO: indent only if debug/verbose level is set... (need to lookup how to do that)
                #       display.verbosity > 1  ?
                json.dump(cache_data, cache_fp, indent=2)
        except IOError as e:
            display.v(f"Unable to save cache file at:  {cache_file} due to {e}")
            return False
        return True

    def load_cached_execution(self,
                              cache_file: Path,
                              source: str) -> dict:
        try:
            with open(cache_file) as cache_fp:
                cache_data = json.load(cache_fp)
        except IOError as e:
            display.vvv(f"Unable to load cache file at:  {cache_file} due to {e}")
            return {}

        if cache_data["version"] != collection_version:
            display.v(f"Invalidating cache due to version mismatch. {cache_data['version']} vs {collection_version}")
            return {}

        # Check to see if the 'file' (dest) value matches the cached fingerprint.
        cached_output_file = Path(cache_data["outputs"]["archive"])
        try:
            output_fp_live = fingerprint_stat(cached_output_file)
        except IOError as e:
            display.v("Removing cached record due to missing output file.  "
                      f"Deleting {cache_file} because the named output file {cached_output_file} cannot be found.  {e}")
            # with suppress:
            if True:
                cache_file.remove()

        output_fp_cache = cache_data["output_fingerprint"]

        if output_fp_cache != output_fp_live:
            display.v(f"Cache mismatch because {cached_output_file} changed.  {output_fp_cache} != {output_fp_live}.  "
                      "If this happens frequently, it could be due to inadequate cache subdivisions.  "
                      "Common solutions to this is diversifying the output 'file' name using variables or "
                      "by adding '[[ layers_hash ]]' if role-specific ksconf layers are in use.")
            return {}

        fileset_cache = FileSet.from_cache(cache_data["source"], fingerprint=fingerprint_stat)
        fileset_live = FileSet.from_filesystem(Path(source), fingerprint=fingerprint_stat)

        if fileset_cache != fileset_live:
            display.v("Cache mismatch due to change(s) in source directory")
            # TODO:  Show some kind of additional details.  File count or possible file with the most recent mtime? ...
            # display.vv("Cache mismatch due to changes to source directory")
            return {}
        else:
            return cache_data

    def run(self, tmp=None, task_vars=None):
        ''' handler for ksconf app packaging operation '''
        if task_vars is None:
            task_vars = dict()
        result = super(ActionModule, self).run(tmp, task_vars)
        del tmp

        validation_result, params = self.validate_argument_spec(
            argument_spec=dict(
                source=dict(type="path", required=True),
                file=dict(type="path", required=True),
                encrypt=dict(type="str",
                             choices=["false", "vault"],
                             default="false"),
                # TODO:  Add a 3rd option to automatically vault when any source files are vaulted
                block=dict(type="list", elements="str", default=[]),
                layer_method=dict(type="str",
                                  choices=["auto", "dir.d", "disable"],
                                  default="dir.d"),
                layers=dict(type="list", default=[],
                            elements="dict",
                            options=dict(include=dict(type="str", default=None),
                                         exclude=dict(type="str", default=None),
                                         ),
                            mutually_exclusive=[("include", "exclude")],
                            required_one_of=[("include", "exclude")]
                            ),
                local=dict(type="str",
                           choices=["preserve", "block", "promote"],
                           default="preserve"
                           ),
                enable_handler=dict(type="list", elements="str", default=[]),
                # Do we need 'NO_LOG' here to protect sensitive information?
                template_vars=dict(type="dict", default=None, required=False),
                follow_symlink=dict(type="bool", default=False),
                app_name=dict(type="str", default=None),
                context=dict(type="dict", default=None),
                cache_storage=dict(type="path", default="~/.cache/cdillc-splunk-ksconf-package")
            )
        )
        # Does something need to be done with `validation_result`?

        source = params["source"]
        dest_file = params["file"]
        encrypt = params["encrypt"]
        block = params["block"]
        layer_method = params["layer_method"]
        layers = params["layers"]
        enable_handler = set(params["enable_handler"] or [])
        template_vars = params["template_vars"] or {}
        local = params["local"]
        follow_symlink = boolean(params["follow_symlink"])
        app_name = params["app_name"]
        cache_storage = Path(params["cache_storage"])

        vault: VaultLib = self._loader._vault
        vault_editor = VaultEditor(vault)

        # Convert any [[var]] --> {{var}} for ksconf
        dest_file = translate_ksconf_vars(dest_file)
        app_name = translate_ksconf_vars(app_name)

        # Copy 'context' through as-is
        if params["context"]:
            result["context"] = params["context"]

        for handler_name in enable_handler:
            # TODO:  Add error checking here to give better exceptions to caller
            layer_file_factory.enable(handler_name)

        if template_vars and not enable_handler.intersection(TEMPLATE_HANDLERS):
            # This is not technically an error, but likely to be a mistake.
            display.warning("Setting 'template_vars' without enabling a template "
                            f"handler (such as {', '.join(TEMPLATE_HANDLERS)} will "
                            "result in all variables being undefined")

        LayerFile_AnsibleJinja2.set_module(self)
        LayerFile_AnsibleVault.set_vault(vault)

        # Enable secure deletion of jinja rendered output, if encryption has been requested
        if encrypt == "vault":
            LayerFile_AnsibleJinja2.use_secure_delete = True

        jinja_handlers_enabled = enable_handler.intersection(JINJA_HANDLERS)
        if len(jinja_handlers_enabled) > 1:
            display.warning("Multiple Jinja template handlers have been enabled.  "
                            f"Please pick one:  {', '.join(jinja_handlers_enabled)}")

        if not os.path.isdir(source):
            return failed(f"The source '{source}' is not a directory or is not accessible.")

        start_time = datetime.datetime.now()

        cache_enabled = True
        # TODO:  Add cache param:  Should be able to (1) enable, (2) disable, and (3) invalidate existing (write-only)

        # Q:  Should encrypt mode disable automatically if 'encrypt' mode is enabled?  (If caching would dump 'template_vars' in the clear...)  Think

        # TODO:  Make caching and templating place nicely:
        #
        #   (0) Ignore the problem, prove out the concept, and encourage intelligently use the 'template_vars' field.
        #
        #   (1) Explicit list of variables (no inheritance):
        #       Require that everything goes through 'template_vars'.  As template_vars is already part of the unique
        #       cache fingerprint, this doesn't require additional code.
        #       Pros: easy to implement so fewer spots for bugs.  Simply disable cache if
        #       Cons: Not super friendly.   ALL variables to be listed explicitly.
        #             Not very smart:  Changes to ANY variable will require a full rebuild, even apps that don't use
        #             variable expansion.
        #            Store more variables on disk, including possible secrets.
        #       One optimization could be that 'template_vars' could accept a list rather than just a dict.  So
        #       variables could be listed, instead of being defined.
        #   (2) Render/fingerprint all templates:
        #       Scan app for templates (may require tweaks/optimizations to the ksconf layer mechanisms) and force
        #       fresh render and capture output checksum, which would be added to the cache fingerprint.  Any changes
        #       would trigger a miss, and full re-packaging.
        #       Pros:  Very use friendly.
        #              No penalties for non-templated apps.
        #              No need to store variable values on disk (most secure option)
        #              Correctly handles complex situations like a variable is removed and replaced with the same static
        #              value.  And this is "free", no additional code needed for this.
        #              Rendered checksum could be stored along with the source file metadata structure.
        #       Cons:  Not the best performance.  Code more complex than #1.
        #   (3) Detect variable use and capture just those.
        #       Store metadata about each template in the fingerprint/cache data.  This would automatically determine
        #       which jinaj2 variables were accessed and automatically record their names/values.
        #       Pros:  User friendly / transparent.
        #       Cons:  Store more variables on disk, including possible secrets.
        #              Complex to code, and may not be possible...
        #              Possible corner cases around situations when variables are added or removed.
        #
        # Will start with #0.  To prove it out.   (Currently leaning towards #1, but #2 may be the best long-term)

        if cache_enabled:
            try:
                # Check for cache of previous execution with the same input params & source directory
                if not cache_storage.is_dir():
                    cache_storage.mkdir()
                cache_id = self.get_cache_id(source, params)
                cache_file = cache_storage / cache_id
            except Exception as e:
                display.display("Unhandled exception while initializing caching system. "
                                f"Cache disabled due to {type(e).__name__}: {e}")
                cache_file = None
                result["cache"] = "failed initialization (disabled)"

            cache_data = {}
            if cache_file:
                try:
                    cache_data = self.load_cached_execution(cache_file, source)
                except Exception as e:
                    display.display("Unhandled exception occurred during cache loading.  "
                                    f"Cache ignored due to {type(e).__name__}: {e}")
                    result["cache"] = "failed load"

            if cache_data:
                result = cache_data["outputs"]
                result["action"] = "cached"
                result["cache"] = "hit"
                result["changed"] = False
                result["old_hash"] = result["new_hash"]  # hash values should always match

                end_time = datetime.datetime.now()
                delta = end_time - start_time
                result["start"] = to_text(start_time)
                result["end"] = to_text(end_time)
                result["delta"] = to_text(delta)
                return result
            else:
                result["cache"] = "miss"
        else:
            result["cache"] = "disabled"

        log_stream = StringIO()

        app_name_source = "set via 'app_name'"
        if not app_name:
            app_name = os.path.basename(source)
            app_name_source = "taken from source directory"

        # TODO:  Add input directory caching/finger printing mechanism to speed-up when unchanged (via ksconf's FileSet)
        display.v(f"Packaging {app_name}   (App name {app_name_source})")
        packager = AppPackager(source, app_name, output=log_stream,
                               template_variables=template_vars)

        # Reminder: move to constructor (once ksconf>=v0.11.5 dependency)
        packager.predictable_mtime = False

        with packager:
            # combine expects as list of (action, pattern)
            layer_filter = [(mode, pattern) for layer in layers
                            for mode, pattern in layer.items() if pattern]
            if layer_filter:
                display.vv(f"Applying layer filter:  {layer_filter}")
            packager.combine(source, layer_filter,
                             layer_method=layer_method,
                             allow_symlink=follow_symlink)
            # Handle local files
            if local == "promote":
                packager.merge_local()
            elif local == "block":
                packager.block_local()
            elif local == "preserve":
                pass
            else:   # pragma: no cover
                # Does argument validation take care of this scenario?  Keep until confirmed....
                return failed(f"Unknown value for 'local': {local}")

            if block:
                display.v(f"Applying blocklist:  {block!r}")
                packager.blocklist(block)

            '''
            if args.set_build or args.set_version:
                packager.update_app_conf(
                    version=args.set_version,
                    build=args.set_build)
            '''

            packager.check()
            # os.system("ls -lR {}".format(packager.app_dir))

            archive_base = packager.app_name.lower().replace("-", "_")

            # Should we default 'dest' if no value is given???? -- this seems problematic
            # (at least we need to be more specific, like include a hash of all found layers??)
            dest = dest_file or "{}-{{{{version}}}}.tgz".format(archive_base)

            # Check manifest of existing 'dest' archive to enable idempotent operation
            archive_path = Path(packager.expand_var(dest))

            new_manifest = packager.make_manifest(calculate_hash=True)
            existing_manifest = None
            result["encryption"] = "false"
            decrypted_size = None

            # Make this idempotent by checking for the output tarball, and determining if the app content changed
            if archive_path.is_file():
                if is_vault_file(archive_path):
                    with temp_decrypt(archive_path, vault,
                                      clone_mtime=True,
                                      log_callback=display.vv) as decrypted_file:
                        existing_manifest = load_manifest_for_archive(decrypted_file,
                                                                      permanent_archive=archive_path,
                                                                      log_callback=display.v)
                        result["encryption"] = "vault"
                        decrypted_size = decrypted_file.stat().st_size
                else:
                    # Check existing manifest for for non-encrypted archive
                    existing_manifest = load_manifest_for_archive(archive_path,
                                                                  log_callback=display.v)

                if existing_manifest.hash == new_manifest.hash:
                    if encrypt != result["encryption"]:
                        # Content matches, but 'encrypt' field changed
                        if encrypt == "vault":
                            resulting_action = "encrypt"
                        else:
                            resulting_action = "decrypt"
                    else:
                        resulting_action = "unchanged"
                else:
                    resulting_action = "updated"
            else:
                resulting_action = "created"

            # Apply any necessary changes
            if resulting_action != "unchanged":
                archive_path2 = packager.make_archive(dest)
                assert str(archive_path) == archive_path2
                size = archive_path.stat().st_size

                # Write manifest created by packager to disk
                display.vv(f"creating manifest for new {archive_path}")
                create_manifest_from_archive(archive_path, None, manifest=new_manifest)

                if encrypt == "vault":
                    vault_editor.encrypt_file(archive_path, secret=None)
                    result["encryption"] = "vault"
                    result["encryption_size"] = archive_path.stat().st_size
            else:
                # No changes; Consistently report unencrypted 'archive_size'
                if encrypt == "vault" and decrypted_size:
                    size = decrypted_size
                    result["encryption_size"] = archive_path.stat().st_size
                else:
                    size = archive_path.stat().st_size

            display.v(f"Archive {resulting_action}:  file={archive_path.name} "
                      f"size={size / 1024.0:.2f}Kb")

            result["action"] = resulting_action
            # Should this be expanded to be an absolute path?
            result["archive"] = os.fspath(archive_path)
            result["app_name"] = packager.app_name
            result["archive_size"] = size

            # TODO: return DELTA, this is basically done. See DeploySequence.from_manifest_transformation(old, new)

            # TODO: return the layer names used.  Currently hidden behind AppPackager's internal call to "combine"
            # result["layers"] = list(...)
            # Ideally, the manifest would contain this metadata as well.

        result["new_hash"] = new_manifest.hash
        result["old_hash"] = existing_manifest.hash if existing_manifest else ""

        # WRITE CACHE HERE!
        if cache_enabled and cache_file:
            self.save_cached_execution(cache_file, source, params, result, archive_path)
            result["cache"] = "created"

        # Fixup the 'layers' output (invocation/module_args/layers); drop empty
        params["layers"] = [{mode: pattern} for layer in layers
                            for mode, pattern in layer.items() if pattern]

        end_time = datetime.datetime.now()
        delta = end_time - start_time

        result["start"] = to_text(start_time)
        result["end"] = to_text(end_time)
        result["delta"] = to_text(delta)
        result["stdout"] = to_text(log_stream.getvalue())

        result["changed"] = resulting_action != "unchanged"

        return result
